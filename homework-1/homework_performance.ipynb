{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 3: Сравнение производительности CPU vs CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Подготовка данных\n",
    "\n",
    "Создайте большие матрицы размеров:\n",
    "1)  64 x 1024 x 1024\n",
    "2)  128 x 512 x 512\n",
    "3) 256 x 256 x 256\n",
    "\n",
    "Заполните их случайными числами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 64x1024x1024\n",
    "t1 = torch.randn(64,1024,1024)\n",
    "\n",
    "# 2) 128x512x512\n",
    "t2 = torch.randn(128,512,512)\n",
    "\n",
    "# 3) 256x256x256\n",
    "t3 = torch.randn(256,256,256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Функция измерения времени\n",
    "\n",
    "Создайте функцию для измерения времени выполнения операций\n",
    "- Используйте torch.cuda.Event() для точного измерения на GPU\n",
    "- Используйте time.time() для измерения на CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Literal\n",
    "\n",
    "Operand = Literal['@', '+', '*', 'T', 'sum']\n",
    "\n",
    "def compute_operation(tensor: torch.Tensor, operand: Operand) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Performs the specified operation on the tensor.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): Input tensor\n",
    "        operand (Operand): Operation to perform\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Result of the operation\n",
    "    \"\"\"\n",
    "    match operand:\n",
    "        case '@':\n",
    "            return tensor @ tensor\n",
    "        case '+':\n",
    "            return tensor + tensor\n",
    "        case '*':\n",
    "            return tensor * tensor\n",
    "        case 'T':\n",
    "            return tensor.T\n",
    "        case 'sum':\n",
    "            return tensor.sum()\n",
    "            \n",
    "def compute_on_gpu(tensor: torch.Tensor, operand: Operand) -> str:\n",
    "    \"\"\"\n",
    "    Measures the execution time of tensor operation on GPU using torch.cuda.Event.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): Input tensor\n",
    "        operand (str): Operation to perform (\"@\", \"+\", \"*\", \"T\", \"sum\")\n",
    "    \n",
    "    Returns:\n",
    "        str: Formatted string with GPU runtime in milliseconds\n",
    "\n",
    "    Raises:\n",
    "        RuntimeError: If CUDA is not available\n",
    "    \"\"\"\n",
    "\n",
    "    if not torch.cuda.is_available():\n",
    "        raise RuntimeError(\"CUDA is not available on this device.\")\n",
    " \n",
    "    tensor = tensor.to('cuda')\n",
    "    \n",
    "    # Create CUDA events for precise timing\n",
    "    start_event = torch.cuda.Event(enable_timing=True)\n",
    "    end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    # Warm-up to ensure accurate timing\n",
    "    _ = compute_operation(tensor, operand)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    # Actual timing\n",
    "    start_event.record()\n",
    "    _ = compute_operation(tensor, operand)\n",
    "    end_event.record()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    elapsed_ms = start_event.elapsed_time(end_event)\n",
    "\n",
    "    return f'GPU \"{operand}\" operation runtime: {elapsed_ms:.1f} ms.'\n",
    "\n",
    "def compute_on_cpu(tensor: torch.Tensor, operand: Operand) -> str:\n",
    "    \"\"\"\n",
    "    Measures the execution time of tensor operation on CPU using time.perf_counter.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): Input tensor\n",
    "        operand (Operand): Operation to perform (\"@\", \"+\", \"*\", \"T\", \"sum\")\n",
    "    \n",
    "    Returns:\n",
    "        str: Formatted string with CPU runtime in milliseconds\n",
    "    \"\"\"\n",
    "    tensor = tensor.to('cpu')\n",
    "    \n",
    "    start = time.time()\n",
    "    _ = compute_operation(tensor, operand)    \n",
    "    end = time.time()\n",
    "\n",
    "    elapsed_ms = (end - start) * 1000\n",
    "    return f'CPU \"{operand}\" operation runtime: {elapsed_ms:.1f} ms.'\n",
    "\n",
    "def measure_operation_time(tensor: torch.Tensor, operand: Operand, use_gpu: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Measures the execution time of tensor operation on CPU or GPU.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): Input tensor to perform operation on\n",
    "        operand (Operand): Operation to perform. Available operations:\n",
    "            - \"@\": Matrix multiplication (tensor @ tensor)\n",
    "            - \"+\": Element-wise addition (tensor + tensor)\n",
    "            - \"*\": Element-wise multiplication (tensor * tensor)  \n",
    "            - \"T\": Transpose operation\n",
    "            - \"sum\": Sum all elements\n",
    "        use_gpu (bool, optional): Whether to use GPU for computation. \n",
    "                                 Defaults to False (CPU).\n",
    "    \n",
    "    Returns:\n",
    "        str: Formatted string containing device type, operation, and runtime in milliseconds\n",
    "        \n",
    "    Raises:\n",
    "        RuntimeError: If GPU is requested but CUDA is not available\n",
    "    \n",
    "    Example:\n",
    "        >>> tensor = torch.randn(100, 100)\n",
    "        >>> result = measure_operation_time(tensor, \"@\", use_gpu=True)\n",
    "        >>> print(result)\n",
    "        GPU \"@\" operation runtime: 1.23 ms\n",
    "    \"\"\"\n",
    "    if use_gpu:\n",
    "        return compute_on_gpu(tensor, operand)\n",
    "    else:\n",
    "        return compute_on_cpu(tensor, operand)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Сравнение операций\n",
    "\n",
    "Сравните время выполнения следующих операций на CPU и CUDA:\n",
    "\n",
    "1. Матричное умножение (torch.matmul)\n",
    "2. Поэлементное сложение\n",
    "3. Поэлементное умножение\n",
    "4. Транспонирование\n",
    "5. Вычисление суммы всех элементов\n",
    "\n",
    "Для каждой операции:\n",
    "1. Измерьте время на CPU\n",
    "2. Измерьте время на GPU (если доступен)\n",
    "3. Вычислите ускорение (speedup)\n",
    "4. Выведите результаты в табличном виде"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1024, 1024]): \n",
      " GPU \"@\" operation runtime: 29.3 ms.\n",
      " CPU \"@\" operation runtime: 226.6 ms.\n",
      "\n",
      "torch.Size([128, 512, 512]): \n",
      " GPU \"@\" operation runtime: 7.2 ms.\n",
      " CPU \"@\" operation runtime: 58.1 ms.\n",
      "\n",
      "torch.Size([256, 256, 256]): \n",
      " GPU \"@\" operation runtime: 1.9 ms.\n",
      " CPU \"@\" operation runtime: 16.1 ms.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) Матричное умножение\n",
    "\n",
    "print(f'{t1.shape}: \\n {measure_operation_time(t1, \"@\", use_gpu=True)}\\n {measure_operation_time(t1, '@')}\\n')\n",
    "print(f'{t2.shape}: \\n {measure_operation_time(t2, \"@\", use_gpu=True)}\\n {measure_operation_time(t2, '@')}\\n')\n",
    "print(f'{t3.shape}: \\n {measure_operation_time(t3, \"@\", use_gpu=True)}\\n {measure_operation_time(t3, '@')}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1024, 1024]): \n",
      " GPU \"+\" operation runtime: 3.0 ms.\n",
      " CPU \"+\" operation runtime: 24.2 ms.\n",
      "\n",
      "torch.Size([128, 512, 512]): \n",
      " GPU \"+\" operation runtime: 1.5 ms.\n",
      " CPU \"+\" operation runtime: 12.4 ms.\n",
      "\n",
      "torch.Size([256, 256, 256]): \n",
      " GPU \"+\" operation runtime: 0.8 ms.\n",
      " CPU \"+\" operation runtime: 6.3 ms.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2) Поэлементное сложение\n",
    "print(f'{t1.shape}: \\n {measure_operation_time(t1, \"+\", use_gpu=True)}\\n {measure_operation_time(t1, '+')}\\n')\n",
    "print(f'{t2.shape}: \\n {measure_operation_time(t2, \"+\", use_gpu=True)}\\n {measure_operation_time(t2, '+')}\\n')\n",
    "print(f'{t3.shape}: \\n {measure_operation_time(t3, \"+\", use_gpu=True)}\\n {measure_operation_time(t3, '+')}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1024, 1024]): \n",
      " GPU \"*\" operation runtime: 3.0 ms.\n",
      " CPU \"*\" operation runtime: 27.8 ms.\n",
      "\n",
      "torch.Size([128, 512, 512]): \n",
      " GPU \"*\" operation runtime: 1.5 ms.\n",
      " CPU \"*\" operation runtime: 13.7 ms.\n",
      "\n",
      "torch.Size([256, 256, 256]): \n",
      " GPU \"*\" operation runtime: 0.8 ms.\n",
      " CPU \"*\" operation runtime: 6.4 ms.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3) Поэлементное умножение\n",
    "print(f'{t1.shape}: \\n {measure_operation_time(t1, \"*\", use_gpu=True)}\\n {measure_operation_time(t1, '*')}\\n')\n",
    "print(f'{t2.shape}: \\n {measure_operation_time(t2, \"*\", use_gpu=True)}\\n {measure_operation_time(t2, '*')}\\n')\n",
    "print(f'{t3.shape}: \\n {measure_operation_time(t3, \"*\", use_gpu=True)}\\n {measure_operation_time(t3, '*')}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1024, 1024]): \n",
      " GPU \"T\" operation runtime: 0.0 ms.\n",
      " CPU \"T\" operation runtime: 0.0 ms.\n",
      "\n",
      "torch.Size([128, 512, 512]): \n",
      " GPU \"T\" operation runtime: 0.0 ms.\n",
      " CPU \"T\" operation runtime: 0.0 ms.\n",
      "\n",
      "torch.Size([256, 256, 256]): \n",
      " GPU \"T\" operation runtime: 0.0 ms.\n",
      " CPU \"T\" operation runtime: 0.0 ms.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4) Транспонирование\n",
    "print(f'{t1.shape}: \\n {measure_operation_time(t1, \"T\", use_gpu=True)}\\n {measure_operation_time(t1, 'T')}\\n')\n",
    "print(f'{t2.shape}: \\n {measure_operation_time(t2, \"T\", use_gpu=True)}\\n {measure_operation_time(t2, 'T')}\\n')\n",
    "print(f'{t3.shape}: \\n {measure_operation_time(t3, \"T\", use_gpu=True)}\\n {measure_operation_time(t3, 'T')}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1024, 1024]): \n",
      " GPU \"sum\" operation runtime: 1.4 ms.\n",
      " CPU \"sum\" operation runtime: 6.6 ms.\n",
      "\n",
      "torch.Size([128, 512, 512]): \n",
      " GPU \"sum\" operation runtime: 0.7 ms.\n",
      " CPU \"sum\" operation runtime: 3.4 ms.\n",
      "\n",
      "torch.Size([256, 256, 256]): \n",
      " GPU \"sum\" operation runtime: 0.4 ms.\n",
      " CPU \"sum\" operation runtime: 1.7 ms.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5) Вычисление суммы всех элементов\n",
    "print(f'{t1.shape}: \\n {measure_operation_time(t1, \"sum\", use_gpu=True)}\\n {measure_operation_time(t1, 'sum')}\\n')\n",
    "print(f'{t2.shape}: \\n {measure_operation_time(t2, \"sum\", use_gpu=True)}\\n {measure_operation_time(t2, 'sum')}\\n')\n",
    "print(f'{t3.shape}: \\n {measure_operation_time(t3, \"sum\", use_gpu=True)}\\n {measure_operation_time(t3, 'sum')}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Матрица 64x1024x1024:**\n",
    "| Операция  | CPU (мс) | GPU (мс) | Ускорение |\n",
    "|------------------------|----------|----------|------------|\n",
    "| Матричное умножение (@)|   226.6  |   29.3   |   7.7×    |\n",
    "| Поэлементное cложение (+) |    24.2  |    3.0   |   8.1×    |\n",
    "| Поэлементное умножение (*) |  27.8  |    3.0   |   9.3×    |\n",
    "| Транспонирование (T)   |    0.0  |    0.0   |    -   |\n",
    "| Суммирование (sum)     |    6.6  |    1.4   |    4.7×    |\n",
    "\n",
    "\n",
    "**Матрица 128x512x512:**\n",
    "| Операция  | CPU (мс) | GPU (мс) | Ускорение |\n",
    "|------------------------|----------|----------|------------|\n",
    "| Матричное умножение (@)|   58.1  |   7.2   |   8.1×    |\n",
    "| Поэлементное cложение (+) |    12.4  |    1.5   |   8.3×    |\n",
    "| Поэлементное умножение (*) |  13.7  |    1.5   |   9.1×    |\n",
    "| Транспонирование (T)   |    0.0  |    0.0   |    -   |\n",
    "| Суммирование (sum)     |    3.4  |    0.7   |    4.9×    |\n",
    "\n",
    "\n",
    "**Матрица 256x256x256:**\n",
    "| Операция  | CPU (мс) | GPU (мс) | Ускорение |\n",
    "|------------------------|----------|----------|------------|\n",
    "| Матричное умножение (@)|   16.1  |   1.9   |   8.5×    |\n",
    "| Поэлементное cложение (+) |    6.3  |    0.8   |   7.9×    |\n",
    "| Поэлементное умножение (*) |  6.4  |    0.8   |   8.0×    |\n",
    "| Транспонирование (T)   |    0.0  |    0.0   |    -   |\n",
    "| Суммирование (sum)     |    1.7  |    0.4   |    4.3×    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Анализ результатов\n",
    "\n",
    "Проанализируйте результаты:\n",
    "\n",
    "1. Какие операции получают наибольшее ускорение на GPU?\n",
    "2. Почему некоторые операции могут быть медленнее на GPU?\n",
    "3. Как размер матриц влияет на ускорение?\n",
    "4. Что происходит при передаче данных между CPU и GPU?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Какие операции получают наибольшее ускорение на GPU?**\n",
    "\n",
    "Наибольшее ускорение получают операции `@`, `+` и `*`:\n",
    "\n",
    "- Поэлементное умножение (`*`): 8.0-9.3x\n",
    "- Поэлементное сложение (`+`): 7.9-8.3x\n",
    "- Матричное умножение (`@`): 7.7-8.5x\n",
    "\n",
    "Высокое ускорение обуславливается тем, что все эти поэлементные операции идеально подходят для массивного параллелизма GPU.\n",
    "\n",
    "Суммирование (`sum`) показывает наименьшее ускорение (4.3-4.9x), т.к. происходит редукция данных (объединение всех элементов в одно значение). \n",
    "\n",
    "**2. Почему некоторые операции могут быть медленнее на GPU?**\n",
    "\n",
    "Каждая операция требует запуска CUDA-ядра, что несёт накладные расходы. Для быстрых операций это может превышать время самих вычислений.\n",
    "\n",
    "**3. Как размер матриц влияет на ускорение?**\n",
    "\n",
    "Тенденции по размерам:\n",
    "| Размер  | Матричное умножение | Поэлементные операции | Суммирование |\n",
    "|------------------------|----------|----------|------------|\n",
    "| 64x1024x1024|   7.7x  |   8.1-9.3x   |   4.7×    |\n",
    "| 128x512x512 |    8.1x  |    8.3-9.1x   |   4.9×    |\n",
    "| 256x256x256 |  8.5x  |    7.9-8.0x  |   4.3×    |\n",
    "\n",
    "Ускорение остаётся стабильным для всех размеров.\n",
    "\n",
    "**4. Что происходит при передаче данных между CPU и GPU?**\n",
    "\n",
    "Данные копируются через PCIe шину из CPU RAM в GPU VRAM, что в разы медленнее внутренней GPU памяти. Из-за этого накладные расходы на передачу часто превышают время самих вычислений, поэтому GPU эффективен только для больших объемов данных или длительных операций."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
